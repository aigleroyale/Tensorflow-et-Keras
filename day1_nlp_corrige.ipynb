{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atelier DAY 1 :  classer du texte \n",
    "\n",
    "L’objectif de cet atelier est d'apprendre à classer du texte dans deux classes : \"positif\" codé par 1 et \"négatif\" codé par 0. L'objectif est de\n",
    "- donner des pistes sur le traitement de données textuelles \n",
    "- faire tourner une logistique / bayes naif\n",
    "\n",
    "Les fichiers IMDB avec lesquels nous travaillons sont disponibles au format python\n",
    "\n",
    "- `train_NLP.pkl` contient deux objets : les *critiques* et les *labels* associés\n",
    "- `test_NLP.pkl` contient deux objets : les *critiques* et les *labels* associés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Table des matières\n",
    "\n",
    "[1. Préliminaires ](#basics)<br>\n",
    "[2. Bases de travail ](#data)<br>\n",
    "[3. Modélisations ](#model)<br>\n",
    "[4. Performance](#perf)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basics'></a>\n",
    "# 1. Préliminaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url_train = 'https://stephanegaiffas.github.io/files/formation_cnrs/train_NLP.pkl.gz'\n",
    "url_test = 'https://stephanegaiffas.github.io/files/formation_cnrs/test_NLP.pkl.gz'\n",
    "r_train = requests.get(url_train)\n",
    "r_test = requests.get(url_test)\n",
    "\n",
    "# Votre chemin. Par defaut celui du notebook\n",
    "path_data = '.'\n",
    "\n",
    "with open(os.path.join(path_data, 'train_NLP.pkl.gz'), 'wb') as f:\n",
    "    f.write(r_train.content)\n",
    "\n",
    "with open(os.path.join(path_data, 'test_NLP.pkl.gz'), 'wb') as f:\n",
    "    f.write(r_test.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement base de travail\n",
    "import pickle as pkl\n",
    "import gzip\n",
    "\n",
    "with gzip.open(os.path.join(path_data, 'train_NLP.pkl.gz'), 'rb') as f:\n",
    "    train = pkl.load(f)\n",
    "    \n",
    "x_train, y_train = train['critiques'], train['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Visualisation des donnees\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "print('Nb de critiques cinema', len(x_train) )\n",
    "print(pd.DataFrame(y_train)[0].value_counts())\n",
    "print('')\n",
    "ind = random.randint(0, 12500)\n",
    "print(y_train[ind])\n",
    "print(x_train[ind])\n",
    "\n",
    "print('')\n",
    "ind = random.randint(12500,25000)\n",
    "print(y_train[ind])\n",
    "print(x_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement base de test\n",
    "with gzip.open(os.path.join(path_data, 'test_NLP.pkl.gz'), 'rb') as f:\n",
    "    test = pkl.load(f)\n",
    "    \n",
    "x_test, y_test = test['critiques'], test['labels']\n",
    "\n",
    "# Comptage\n",
    "print('Nb de critiques cinema', len(x_test))\n",
    "print(pd.DataFrame(y_test)[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "# 2. Bases de travail\n",
    "\n",
    "Les données brutes *textuelles* nécessitent d'être transformées en *tableau de nombres* pour utiliser les algorithmes. Les choix proposés:\n",
    "\n",
    "- coder chaque **mot** par un nombre \n",
    "    - restreindre le nombre de mots aux **plus fréquents** rencontrés dans la base d'apprentissage\n",
    "    - standardiser chaque ligne de texte ==> **même nombre de mots** (éventuellement, compléter par des zeros)\n",
    "    \n",
    "- compter le **nombre d'occurences** des mots\n",
    "\n",
    "### Codage des mots \n",
    "\n",
    "On transforme la suite de textes en un tableau de variables qualitatives. \n",
    "\n",
    "- les lignes sont le numéro de la critique\n",
    "- la première (ième) colonne est le premier (jième) mot (détecté dans le dictionnaire)\n",
    "\n",
    "Puis, on code chaque mot. Remarquons que l'ordre d'appartion des mots est préservé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########## preprocessing  des data      \n",
    "# import tensorflow.preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "#tuning\n",
    "max_mots_dico  = 3000           # on prend les 3000 mots les plus frequents du dico\n",
    "max_len_critique = 200          # on prend les 200 premiers mots de chaque critique qui apparaissent dans le dico\n",
    "\n",
    "#restriction données pour rapidité\n",
    "n_train = 25000                  # on restreint notre base ==> faire varier pour montrer l'importance 200 ne marche pas\n",
    "\n",
    "#transformation\n",
    "tok = Tokenizer(num_words = max_mots_dico)       # prend les + frequents\n",
    "tok.fit_on_texts(x_train)                        # construit le dico a partir du corpus. range du + freq au - freq\n",
    "\n",
    "sequences = tok.texts_to_sequences(x_train)      # code les critiques en entiers\n",
    "mot_code = tok.word_index                        # donne le codage mot <=> entier\n",
    "print('il y a %s uniques tokens' % len(mot_code))\n",
    "\n",
    "xx_train = pad_sequences(sequences, maxlen = max_len_critique)  # formate les critiques codees de longeur maxlen\n",
    "yy_train = pd.Series(y_train)\n",
    "print('Shape of critique tensor:', xx_train.shape)\n",
    "print('Shape of label tensor:', yy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Par souci de rapidité\n",
    "\n",
    "# melange toutes les lignes des données pour ne pas avoir les neg au debut et les pos a la fin\n",
    "indices = np.arange(xx_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "xx_train2 = xx_train[indices]\n",
    "yy_train2 = yy_train[indices]\n",
    "\n",
    "# restiction du set des data\n",
    "xx_train_cod = xx_train2[:n_train]\n",
    "yy_train_cod = yy_train2[:n_train]\n",
    "\n",
    "# distribution des labels\n",
    "print(yy_train_cod.value_counts())\n",
    "print(yy_train_cod.value_counts() / n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xx_train_cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train_cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('codage par ordre de frequence decroissante', mot_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Codage d une critique', [y_train[10]])\n",
    "print('')\n",
    "print('le texte est :',x_train[10])\n",
    "print('')\n",
    "print('le texte codé est :', xx_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'aspect série temporelle est important : on veut avantager les données les plus récentes\n",
    "\n",
    "- nombre de mots > *max_len_critique* ==> tronquage de la séquence au début\n",
    "- nombre de mots < *max_len_critique* ==> ajoût de zéros au début"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LAISSER FAIRE sur TEST : attention le dico est deja donne ==> ne pas re apprendre !\n",
    "sequences = tok.texts_to_sequences(x_test)\n",
    "# code les critiques en entiers avec le meme tokenizer\n",
    "xx_test_cod = pad_sequences(sequences, maxlen = max_len_critique)\n",
    "# transforme les critiques en suite d entiers de longeur maxlen\n",
    "\n",
    "yy_test_cod = pd.Series(y_test)\n",
    "print('Shape of critique tensor:', xx_test_cod.shape)\n",
    "print('Shape of label tensor:', yy_test_cod.shape)\n",
    "\n",
    "# distribution des labels\n",
    "print(yy_test_cod.value_counts())\n",
    "print(yy_test_cod.value_counts() / len(yy_test_cod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre d'occurences\n",
    "\n",
    "On transforme la suite de textes en un tableau de variables quantitatives\n",
    "\n",
    "- les lignes sont le numéro de la critique\n",
    "- la première (ième) colonne est \n",
    "    - 0 si le premier mot du dictionnaire n'apparait pas\n",
    "    - TF * IDF ou TF = term frequency = frequence d'apparition du mot dans le document et IDF=log de l'inverse de la proportion de documents ou le terme apparait\n",
    "\n",
    "Remarquons que l'ordre d'apparition des mots est oublié puisque les colonnes sont dans l'ordre des mots du dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer='word', \n",
    "                       stop_words='english')\n",
    "\n",
    "# construction du dictionnaire adapté à TRAIN et calcul des occurences\n",
    "xx_train_occ = vect.fit_transform(x_train) \n",
    "yy_train_occ = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(xx_train_occ[0:1000, 0:3])\n",
    "# en ligne : les critiques\n",
    "# en colonne : les mots du plus fréquent au moins fréquent dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xx_train_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les critiques n'utilisant qu'un très petit nombre de mots du dictionnaire, la matrice d'occurence est creuse ==> l'affichage ne montre que les termes non nuls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention: \n",
    "# ne pas re-construire un dictionnaire (different!), calculer les occurences avec le dictionnaire construit sur TRAIN\n",
    "xx_test_occ = vect.transform(x_test)\n",
    "yy_test_occ = pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions que l'on se pose \n",
    "\n",
    "- Vaut-il mieux coder les mots ou utiliser le nombre d'occurence ?\n",
    "- La modélisation logistique est-elle performante ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_travail = './'\n",
    "\n",
    "# On sauve tout\n",
    "with open(os.path.join(path_travail, 'imdb_train_cod.pkl'), 'wb') as f:\n",
    "    pkl.dump({'features': xx_train_cod, 'labels': yy_train_cod}, f)\n",
    "\n",
    "with open(os.path.join(path_travail, 'imdb_test_cod.pkl'), 'wb') as f:\n",
    "    pkl.dump({'features': xx_test_cod, 'labels': yy_test_cod}, f)\n",
    "\n",
    "with open(os.path.join(path_travail, 'imdb_train_occ.pkl'), 'wb') as f:\n",
    "    pkl.dump({'features': xx_train_occ, 'labels': yy_train_occ}, f)\n",
    "\n",
    "with open(os.path.join(path_travail, 'imdb_test_occ.pkl'), 'wb') as f:\n",
    "    pkl.dump({'features': xx_test_occ, 'labels': yy_test_occ}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "# 2. Modélisations \n",
    "\n",
    "Nous proposons d'évaluer les performance de l'algorithme **Bayes Naif** en prenant **la logistique L1 pénalisée** comme benchmark (tunée par défaut). \n",
    "\n",
    "La modélisation se fait en trois temps :\n",
    "- on sépare les données : LEARN / TEST ==> déjà fait\n",
    "- on apprend le modèle sur TRAIN\n",
    "- on ré-applique le modèle sur TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle avec pénalisation L1 <== tuning par défaut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "x = xx_train_cod.copy()\n",
    "y = yy_train_cod.copy()\n",
    "\n",
    "# définition du modèle\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "# apprentissage\n",
    "logreg.fit(x, y)                      \n",
    "\n",
    "x = xx_test_cod.copy()\n",
    "y = yy_test_cod.copy()\n",
    "\n",
    "# Prédiction\n",
    "res_test = logreg.predict(x)           \n",
    "temp = pd.Series(res_test, index=y.index)\n",
    "pred_test = pd.concat([y, temp], axis=1) \n",
    "pred_test.rename(columns={1: 'class'}, inplace=True)\n",
    "pred_test.rename(columns={0: 'y'}, inplace=True)\n",
    "\n",
    "# Sauver les scores pour log pénalisation par defaut\n",
    "class_test_L_cod = pred_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.stem(logreg.coef_.ravel(), use_line_collection=True)\n",
    "plt.title('Logistic regression coefficients', fontsize=16)\n",
    "_ = plt.yticks(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,  BernoulliNB\n",
    "\n",
    "x = xx_train_cod.copy()\n",
    "y = yy_train_cod.copy()\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(x,y)\n",
    "\n",
    "x = xx_test_cod.copy()\n",
    "y = yy_test_cod.copy()\n",
    "# Prédiction\n",
    "pred_test = NB.predict(x)\n",
    "\n",
    "# Affichage\n",
    "temp = pd.Series(pred_test, index=y.index)\n",
    "pred_test = pd.concat([y, temp], axis=1)\n",
    "pred_test.rename(columns={0: 'y'}, inplace=True)\n",
    "pred_test.rename(columns={1: 'class'}, inplace=True)\n",
    "\n",
    "# Sauver les scores pour NB\n",
    "class_test_NB_cod = pred_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle avec pénalisation L1 <== tunning par défaut\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "x = xx_train_occ.copy()\n",
    "y = yy_train_occ.copy()\n",
    "\n",
    "# définition du modèle\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "# apprentissage\n",
    "logreg.fit(x, y)                      \n",
    "\n",
    "x = xx_test_occ.copy()\n",
    "y = yy_test_occ.copy()\n",
    "# Prédiction\n",
    "res_test = logreg.predict(x)           \n",
    "\n",
    "# Affichage\n",
    "temp = pd.Series(res_test, index=y.index)\n",
    "pred_test = pd.concat([y, temp], axis=1)\n",
    "pred_test.rename(columns={0: 'y'}, inplace=True)\n",
    "pred_test.rename(columns={1: 'class'}, inplace=True)\n",
    "\n",
    "# Sauver les scores pour log pénalisation par defaut\n",
    "class_test_L_occ = pred_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,  BernoulliNB\n",
    "\n",
    "x = xx_train_occ.copy()\n",
    "y = yy_train_occ.copy()\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(x,y)\n",
    "\n",
    "x = xx_test_occ.copy()\n",
    "y = yy_test_occ.copy()\n",
    "\n",
    "# Prédiction\n",
    "pred_test = NB.predict(x)\n",
    "\n",
    "# Affichage\n",
    "temp = pd.Series(pred_test, index=y.index)\n",
    "pred_test = pd.concat([y, temp], axis=1)\n",
    "pred_test.rename(columns={0: 'y'}, inplace=True)\n",
    "pred_test.rename(columns={1: 'class'}, inplace=True)\n",
    "\n",
    "# Sauver les scores pour NB\n",
    "class_test_NB_occ = pred_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='perf'></a>\n",
    "# 3. PERFORMANCES\n",
    "\n",
    "La performance pour le problème de classification s'analyse sur la base TEST\n",
    "\n",
    "- Matrice de confusion (qui donne les deux erreurs et la puissance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "m_test = class_test_L_cod.copy()\n",
    "\n",
    "print('Sur le test...')\n",
    "print(classification_report(m_test['y'], m_test['class']))\n",
    "print(confusion_matrix(m_test['y'], m_test['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_test = class_test_NB_cod.copy()\n",
    "\n",
    "print('Sur le test...')\n",
    "print(classification_report(m_test['y'], m_test['class']))\n",
    "print(confusion_matrix(m_test['y'], m_test['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_test = class_test_L_occ.copy()\n",
    "\n",
    "print('Sur le test...')\n",
    "print(classification_report(m_test['y'], m_test['class']))\n",
    "print(confusion_matrix(m_test['y'], m_test['class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test = class_test_NB_occ.copy()\n",
    "\n",
    "print('Sur le test...')\n",
    "print(classification_report(m_test['y'], m_test['class']))\n",
    "print(confusion_matrix(m_test['y'], m_test['class']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
